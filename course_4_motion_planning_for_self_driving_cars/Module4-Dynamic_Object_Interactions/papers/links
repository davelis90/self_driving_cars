C. Urmson, C. Baker, J. Dolan, P. Rybski, B. Salesky, W. Whittaker, D. Ferguson, and M. Darms, “Autonomous Driving in Traffic: Boss and the Urban Challenge,” AI Magazine, vol. 30, no. 2, p. 17, 2009. This gives an overview of some of the methods used to handle dynamic obstacles in the DARPA Urban Challenge.


The
world model includes the road network, static
obstacles, tracked vehicles, and the position and
velocity of Boss
Each dynamic obstacle is represented by a series
of oriented rectangles and velocities
Static obstacles are represented in a grid of regu-
larly spaced cells.
Once a dynamic obstacle achieves the state of
observed moving, the cells in the map that it over-
laps are cleared.
The tracking system is divided into
two layers: a sensor layer and a fusion layer (see fig-
ure 4).
The
sensor layer modules perform sensor-specific tasks
such as feature extraction, validation, association,
and proposal and observation generation.
For example, radar
sensors may generate a specific class of false echoes
that can be heuristically filtered, but the filtering
approach would be irrelevant for a lidar or even a
different class of radar. By encapsulating these sen-
sor-specific details within sensor modules we were
able to modularize the algorithms and maintain a
clean, general implementation in the fusion layer.
The future state of
each moving obstacle is generated by either extrap-
olating its track (over short time intervals) or by
using the road network and driving context (for
long time intervals).
Motion planning is responsible for moving the
vehicle safely through the environment. To do
this, it first creates a path toward the goal, then
tracks it by generating a set of candidate trajecto-
ries following the path to varying degrees and
selecting the best collision-free trajectory from this
set.
Then, a model-based
trajectory generation algorithm (Howard et al.
2008) is used to compute dynamically feasible tra-
jectories to these local goals.
The precedence order is determined
using typical driving rules (that is, the first to arrive
has precedence through the intersection and in
cases of simultaneous arrival, yield to the right).
Polygons are computed around
each stop line, extending backward along the
incoming lane by a configurable distance and
exceeding the lane geometry by a configurable
margin. If the front bumper of a moving obstacle
is inside this polygon, it is considered an occupant
of the associated stop line.
The on-road recovery algorithm involves gener-
ating goals at incrementally greater distances down
the current road lane to some maximum distance.
These forward goals (goals 1, 2, 3 in figure 6a) are
constrained to remain in the original lane of trav-
el. If none of the forward goals succeed, a goal is
selected a short distance behind the vehicle (goal
4) with the intent of backing up to provide a new
perspective. After backing up, the sequence of for-
ward goals is allowed to repeat once more with an
offset, after which continued failure triggers high-
er-risk maneuvers. For example, if there is a lane
available in the opposing direction, the road is
eventually marked as blocked, and the system
issues a U-turn goal (goal 5) and attempts to follow
an alternate path to the goal.

